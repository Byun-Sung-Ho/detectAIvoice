{"cells":[{"cell_type":"markdown","id":"361d73a1","metadata":{"papermill":{"duration":0.007011,"end_time":"2024-04-08T18:51:47.130888","exception":false,"start_time":"2024-04-08T18:51:47.123877","status":"completed"},"tags":[],"id":"361d73a1"},"source":["# Imports"]},{"cell_type":"markdown","id":"a0d2de5d","metadata":{"papermill":{"duration":0.007241,"end_time":"2024-04-08T18:51:59.803571","exception":false,"start_time":"2024-04-08T18:51:59.796330","status":"completed"},"tags":[],"id":"a0d2de5d"},"source":["# Config"]},{"cell_type":"markdown","id":"629d3d15-b971-49e2-a410-71b4cd9cbcf4","metadata":{"id":"629d3d15-b971-49e2-a410-71b4cd9cbcf4"},"source":["## Data Pre-processing : MFCC"]},{"cell_type":"markdown","id":"8a682d49","metadata":{"papermill":{"duration":0.007331,"end_time":"2024-04-08T18:52:31.507909","exception":false,"start_time":"2024-04-08T18:52:31.500578","status":"completed"},"tags":[],"id":"8a682d49"},"source":["# Dataset"]},{"cell_type":"markdown","id":"effb3435-cdb7-4a31-b7ef-fc16237cfc4a","metadata":{"id":"effb3435-cdb7-4a31-b7ef-fc16237cfc4a"},"source":["# Define Model"]},{"cell_type":"markdown","id":"b28c4a8c-0219-46bd-bd46-09d0327fe7eb","metadata":{"id":"b28c4a8c-0219-46bd-bd46-09d0327fe7eb"},"source":["# Train & Validation"]},{"cell_type":"markdown","id":"4a482219-ce5e-47ce-90cc-564ceb4e46ff","metadata":{"id":"4a482219-ce5e-47ce-90cc-564ceb4e46ff"},"source":["## Run"]},{"cell_type":"markdown","id":"a978b0e6-b773-423a-93e4-ce463f4d4d84","metadata":{"id":"a978b0e6-b773-423a-93e4-ce463f4d4d84"},"source":["## Inference"]},{"cell_type":"markdown","id":"a8fae66d-8f54-46d5-9201-0f4b0db76e76","metadata":{"id":"a8fae66d-8f54-46d5-9201-0f4b0db76e76"},"source":["## Submission"]},{"cell_type":"code","source":["!pip install librosa torch torchaudio transformers scikit-learn pandas numpy"],"metadata":{"id":"y8DR0CKzTXVV"},"id":"y8DR0CKzTXVV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/dacon/open"],"metadata":{"id":"FXGCjrSpTJUt"},"id":"FXGCjrSpTJUt","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"bbadbd56","metadata":{"papermill":{"duration":12.650384,"end_time":"2024-04-08T18:51:59.788340","exception":false,"start_time":"2024-04-08T18:51:47.137956","status":"completed"},"tags":[],"id":"bbadbd56"},"outputs":[],"source":["import librosa\n","\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","import random\n","\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","\n","import torch\n","import torchmetrics\n","import os"]},{"cell_type":"code","execution_count":null,"id":"2d80cf24-13e8-480c-94eb-2982bb52510d","metadata":{"id":"2d80cf24-13e8-480c-94eb-2982bb52510d"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"id":"f64eb379-e527-46c4-8b12-ead8db628070","metadata":{"id":"f64eb379-e527-46c4-8b12-ead8db628070"},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"]},{"cell_type":"code","execution_count":null,"id":"1a32fb60","metadata":{"papermill":{"duration":0.016983,"end_time":"2024-04-08T18:51:59.828208","exception":false,"start_time":"2024-04-08T18:51:59.811225","status":"completed"},"tags":[],"id":"1a32fb60"},"outputs":[],"source":["class Config:\n","    SR = 32000\n","    N_MFCC = 13\n","    # Dataset\n","    ROOT_FOLDER = './'\n","    # Training\n","    N_CLASSES = 2\n","    BATCH_SIZE = 96\n","    N_EPOCHS = 5\n","    LR = 3e-4\n","    # Others\n","    SEED = 42\n","\n","CONFIG = Config()"]},{"cell_type":"code","execution_count":null,"id":"6700bf8e-7f43-4eac-9bea-25eb1d95fb12","metadata":{"id":"6700bf8e-7f43-4eac-9bea-25eb1d95fb12"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","seed_everything(CONFIG.SEED) # Seed 고정"]},{"cell_type":"code","execution_count":null,"id":"d8c02a7d-dfb6-4f8b-8df1-db2abaa1cb5d","metadata":{"id":"d8c02a7d-dfb6-4f8b-8df1-db2abaa1cb5d"},"outputs":[],"source":["df = pd.read_csv('./train.csv')\n","train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED)"]},{"cell_type":"code","execution_count":null,"id":"d1bdd0ba-fe6e-4efa-b785-af0389c50b56","metadata":{"id":"d1bdd0ba-fe6e-4efa-b785-af0389c50b56"},"outputs":[],"source":["def get_mfcc_feature(df, train_mode=True):\n","    features = []\n","    labels = []\n","    for _, row in tqdm(df.iterrows()):\n","        # librosa패키지를 사용하여 wav 파일 load\n","        y, sr = librosa.load(row['path'], sr=CONFIG.SR)\n","\n","        # librosa패키지를 사용하여 mfcc 추출\n","        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n","        mfcc = np.mean(mfcc.T, axis=0)\n","        features.append(mfcc)\n","\n","        if train_mode:\n","            label = row['label']\n","            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n","            label_vector[0 if label == 'fake' else 1] = 1\n","            labels.append(label_vector)\n","\n","    if train_mode:\n","        return features, labels\n","    return features"]},{"cell_type":"code","execution_count":null,"id":"c5efb058-b659-48bc-a7f8-9e27211ef21c","metadata":{"id":"c5efb058-b659-48bc-a7f8-9e27211ef21c"},"outputs":[],"source":["train_mfcc, train_labels = get_mfcc_feature(train, True)\n","val_mfcc, val_labels = get_mfcc_feature(val, True)"]},{"cell_type":"code","execution_count":null,"id":"d2459913-1bf6-40b9-b07d-402699590b8f","metadata":{"id":"d2459913-1bf6-40b9-b07d-402699590b8f"},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, mfcc, label):\n","        self.mfcc = mfcc\n","        self.label = label\n","\n","    def __len__(self):\n","        return len(self.mfcc)\n","\n","    def __getitem__(self, index):\n","        if self.label is not None:\n","            return self.mfcc[index], self.label[index]\n","        return self.mfcc[index]"]},{"cell_type":"code","execution_count":null,"id":"6c7a462f-e4b3-44d8-8eef-16000d3124d0","metadata":{"id":"6c7a462f-e4b3-44d8-8eef-16000d3124d0"},"outputs":[],"source":["train_dataset = CustomDataset(train_mfcc, train_labels)\n","val_dataset = CustomDataset(val_mfcc, val_labels)"]},{"cell_type":"code","execution_count":null,"id":"dff1c7df-fbe7-4a61-9f66-c55138697eab","metadata":{"id":"dff1c7df-fbe7-4a61-9f66-c55138697eab"},"outputs":[],"source":["train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=CONFIG.BATCH_SIZE,\n","    shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=CONFIG.BATCH_SIZE,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"id":"aba60869-b8a5-46c2-b185-00131161a158","metadata":{"id":"aba60869-b8a5-46c2-b185-00131161a158"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor, Trainer, TrainingArguments\n","\n","# Load and preprocess data\n","data = pd.read_csv('/mnt/data/train (1).csv')\n","def extract_features(file_path):\n","    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n","    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n","    return np.mean(mfccs.T, axis=0)\n","\n","data['features'] = data['path'].apply(lambda x: extract_features(x))\n","data = data.dropna()\n","\n","label_encoder = LabelEncoder()\n","data['label'] = label_encoder.fit_transform(data['label'])\n","\n","X = np.array(data['features'].tolist())\n","y = data['label'].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.long)\n","y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\", num_labels=2)\n","processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n",")\n","\n","train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n","test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")\n","\n","trainer.train()\n","\n","predictions = trainer.predict(test_dataset)\n","pred_labels = np.argmax(predictions.predictions, axis=1)\n","\n","output_df = pd.DataFrame({'id': data['id'][X_test.index], 'label': label_encoder.inverse_transform(pred_labels)})\n","output_df.to_csv('predictions.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"id":"2a7253de-ce9a-45a8-b71f-7752e427941c","metadata":{"id":"2a7253de-ce9a-45a8-b71f-7752e427941c"},"outputs":[],"source":["from sklearn.metrics import roc_auc_score\n","\n","def train(model, optimizer, train_loader, val_loader, device):\n","    model.to(device)\n","    criterion = nn.BCELoss().to(device)\n","\n","    best_val_score = 0\n","    best_model = None\n","\n","    for epoch in range(1, CONFIG.N_EPOCHS+1):\n","        model.train()\n","        train_loss = []\n","        for features, labels in tqdm(iter(train_loader)):\n","            features = features.float().to(device)\n","            labels = labels.float().to(device)\n","\n","            optimizer.zero_grad()\n","\n","            output = model(features)\n","            loss = criterion(output, labels)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss.append(loss.item())\n","\n","        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n","        _train_loss = np.mean(train_loss)\n","        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}]')\n","\n","        if best_val_score < _val_score:\n","            best_val_score = _val_score\n","            best_model = model\n","\n","    return best_model\n","\n","def multiLabel_AUC(y_true, y_scores):\n","    auc_scores = []\n","    for i in range(y_true.shape[1]):\n","        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n","        auc_scores.append(auc)\n","    mean_auc_score = np.mean(auc_scores)\n","    return mean_auc_score\n","\n","def validation(model, criterion, val_loader, device):\n","    model.eval()\n","    val_loss, all_labels, all_probs = [], [], []\n","\n","    with torch.no_grad():\n","        for features, labels in tqdm(iter(val_loader)):\n","            features = features.float().to(device)\n","            labels = labels.float().to(device)\n","\n","            probs = model(features)\n","\n","            loss = criterion(probs, labels)\n","\n","            val_loss.append(loss.item())\n","\n","            all_labels.append(labels.cpu().numpy())\n","            all_probs.append(probs.cpu().numpy())\n","\n","        _val_loss = np.mean(val_loss)\n","\n","        all_labels = np.concatenate(all_labels, axis=0)\n","        all_probs = np.concatenate(all_probs, axis=0)\n","\n","        # Calculate AUC score\n","        auc_score = multiLabel_AUC(all_labels, all_probs)\n","\n","    return _val_loss, auc_score"]},{"cell_type":"code","execution_count":null,"id":"e97644a0-2385-4e16-ab02-ecf787ac061c","metadata":{"id":"e97644a0-2385-4e16-ab02-ecf787ac061c"},"outputs":[],"source":["\n","import pandas as pd\n","import numpy as np\n","import torch\n","from sklearn.preprocessing import LabelEncoder\n","from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor, Trainer, TrainingArguments\n","\n","# Load and preprocess data\n","data = pd.read_csv('/mnt/data/train (1).csv')\n","def extract_features(file_path):\n","    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n","    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n","    return np.mean(mfccs.T, axis=0)\n","\n","data['features'] = data['path'].apply(lambda x: extract_features(x))\n","data = data.dropna()\n","\n","label_encoder = LabelEncoder()\n","data['label'] = label_encoder.fit_transform(data['label'])\n","\n","X = np.array(data['features'].tolist())\n","y = data['label'].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","X_train = torch.tensor(X_train, dtype=torch.float32)\n","X_test = torch.tensor(X_test, dtype=torch.float32)\n","y_train = torch.tensor(y_train, dtype=torch.long)\n","y_test = torch.tensor(y_test, dtype=torch.long)\n","\n","model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-base-960h\", num_labels=2)\n","processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n","\n","training_args = TrainingArguments(\n","    output_dir='./results',\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=16,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n",")\n","\n","train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n","test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=test_dataset,\n",")\n","\n","trainer.train()\n","\n","predictions = trainer.predict(test_dataset)\n","pred_labels = np.argmax(predictions.predictions, axis=1)\n","\n","output_df = pd.DataFrame({'id': data['id'][X_test.index], 'label': label_encoder.inverse_transform(pred_labels)})\n","output_df.to_csv('predictions.csv', index=False)\n"]},{"cell_type":"code","execution_count":null,"id":"76141516-342f-4f0f-8f75-20700f284792","metadata":{"id":"76141516-342f-4f0f-8f75-20700f284792"},"outputs":[],"source":["test = pd.read_csv('./test.csv')\n","test_mfcc = get_mfcc_feature(test, False)\n","test_dataset = CustomDataset(test_mfcc, None)\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=CONFIG.BATCH_SIZE,\n","    shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"id":"5889b493-d760-4cac-9ced-c3715195e8be","metadata":{"id":"5889b493-d760-4cac-9ced-c3715195e8be"},"outputs":[],"source":["def inference(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","        for features in tqdm(iter(test_loader)):\n","            features = features.float().to(device)\n","\n","            probs = model(features)\n","\n","            probs  = probs.cpu().detach().numpy()\n","            predictions += probs.tolist()\n","    return predictions"]},{"cell_type":"code","execution_count":null,"id":"cd74fe5f-82f1-4ad7-818f-509e1bea642d","metadata":{"id":"cd74fe5f-82f1-4ad7-818f-509e1bea642d"},"outputs":[],"source":["preds = inference(infer_model, test_loader, device)"]},{"cell_type":"code","execution_count":null,"id":"3f8314c4-1dce-4f79-9f3d-77d320a3746e","metadata":{"id":"3f8314c4-1dce-4f79-9f3d-77d320a3746e"},"outputs":[],"source":["submit = pd.read_csv('./sample_submission.csv')\n","submit.iloc[:, 1:] = preds\n","submit.head()"]},{"cell_type":"code","execution_count":null,"id":"e28d71bc-6703-40f7-9716-a0ef897eca83","metadata":{"id":"e28d71bc-6703-40f7-9716-a0ef897eca83"},"outputs":[],"source":["submit.to_csv('./baseline_submit.csv', index=False)"]},{"cell_type":"code","source":[],"metadata":{"id":"Az9dC3UbTN0m"},"id":"Az9dC3UbTN0m","execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}